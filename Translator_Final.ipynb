{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translator_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLzRHqst6P5saSPuCb7w1f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpY7SuBM6j1I",
        "colab_type": "code",
        "outputId": "15385d26-bf4e-47e9-c7ee-cef4e1d580d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIETRIloG8hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "from keras_preprocessing.text import  Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQoSyhjS7fbd",
        "colab_type": "text"
      },
      "source": [
        "**Language Translation**<br>English to French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDltitkd7EJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper Function\n",
        "import os\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nq0agNE8S-0",
        "colab_type": "code",
        "outputId": "ecf5cd3b-aa62-4e93-d8d6-b10f06019d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Getting the data\n",
        "\n",
        "source_path ='/content/drive/My Drive/Colab Notebooks/data/small_vocab_en'\n",
        "target_path = '/content/drive/My Drive/Colab Notebooks/data/small_vocab_fr'\n",
        "#loading English data\n",
        "source_text = load_data(source_path)\n",
        "#loading French data\n",
        "target_text = load_data(target_path)\n",
        "\n",
        "print('Loading Complete')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L54c0yeEOs1",
        "colab_type": "text"
      },
      "source": [
        "**Sample data and its french transaltion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MsSZs1G8yzE",
        "colab_type": "code",
        "outputId": "1d07be82-7048-417a-c9ec-a7ba2963e525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print('small_vocab_en Line {} : {}'.format(1,source_text[0]))\n",
        "print('small_vocab_fr Line {} : {}'.format(1, target_text[0]))\n",
        "print('small_vocab_en Line {} : {}'.format(2,source_text[1]))\n",
        "print('small_vocab_fr Line {} : {}'.format(2, target_text[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "small_vocab_en Line 1 : new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "small_vocab_fr Line 1 : new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "small_vocab_en Line 2 : the united states is usually chilly during july , and it is usually freezing in november .\n",
            "small_vocab_fr Line 2 : les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDnj8ajtGwqX",
        "colab_type": "text"
      },
      "source": [
        "**Vocabulary**<br> Let's look at the vocabulary of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOmfChtsFEiE",
        "colab_type": "code",
        "outputId": "6c7d84a1-19e0-4ee1-a46b-4bb954569f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "english_word_counter = collections.Counter([word for sentence in source_text for word in sentence.split()])\n",
        "french_word_counter = collections.Counter([word for sentence in target_text for word in sentence.split() ])\n",
        "\n",
        "print('{} of English Words'.format(len([word for sentence in source_text for word in sentence.split()])))\n",
        "print('10 most common English words {}'.format(english_word_counter.most_common(10)))\n",
        "print('{} of French Words'.format(len([word for sentence in target_text for word in sentence.split()])))\n",
        "print('10 most common French words {}'.format(french_word_counter.most_common(10)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1823250 of English Words\n",
            "10 most common English words [('is', 205858), (',', 140897), ('.', 129039), ('in', 75525), ('it', 75137), ('during', 74933), ('the', 67628), ('but', 63987), ('and', 59850), ('sometimes', 37746)]\n",
            "1961295 of French Words\n",
            "10 most common French words [('est', 196809), ('.', 135619), (',', 123135), ('en', 105768), ('il', 84079), ('les', 65255), ('mais', 63987), ('et', 59851), ('la', 49861), ('parfois', 37746)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSKYc9udOV6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: tokenized x data\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    tokenized_x =Tokenizer()\n",
        "    tokenized_x.fit_on_texts(x)\n",
        "    return tokenized_x.texts_to_sequences(x),tokenized_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9rbQaflK_KZ",
        "colab_type": "text"
      },
      "source": [
        "**Tokenization of data**<br>tokenization function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iZ48adyMutO",
        "colab_type": "code",
        "outputId": "711803be-f92b-4dea-b44c-203b5622d94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Sample tokenization\n",
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "text_tokenized,x_tokenizer= tokenize(text_sentences)\n",
        "print(text_tokenized)\n",
        "print(x_tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 4, 5, 6, 7, 1, 8, 9], [10, 11, 12, 2, 13, 14, 15, 16, 3, 17], [18, 19, 3, 20, 21]]\n",
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Eh6R8fPhoB",
        "colab_type": "text"
      },
      "source": [
        "**Padding**<br>for making all the sequences of same length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSm0HybUM5Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(x,length=None):\n",
        "    \"\"\"Padding x\n",
        "        params:\n",
        "        x: list of sequences\n",
        "        length: length to Pad the sequence to if None is provided use length of the longest sequence\n",
        "        return: padded numpy array of sequence\n",
        "    \"\"\"\n",
        "    return pad_sequences(x,maxlen=length,truncating='post',padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUSXnUNaQuGr",
        "colab_type": "code",
        "outputId": "d7bef283-c63e-4b76-9008-6c5103f76180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#test pad\n",
        "test_pad = pad(text_tokenized)\n",
        "print(test_pad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  4  5  6  7  1  8  9  0]\n",
            " [10 11 12  2 13 14 15 16  3 17]\n",
            " [18 19  3 20 21  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYkZ-D7UYQeA",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess Pipeline**<br>Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oxpKc5GQ5q3",
        "colab_type": "code",
        "outputId": "7867bfc5-3af5-44f9-ad40-a32eebbba713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def preprocess(x,y):\n",
        "    \"\"\"\n",
        "    Pre-process x and y\n",
        "    params:\n",
        "    x: Feature list of sentences\n",
        "    y: Label list of sentences\n",
        "    return :\n",
        "    return preprocessed_x, pre_processed_y\n",
        "    \"\"\"\n",
        "    preprocessed_x,x_tokenizer = tokenize(x)\n",
        "    preprocessed_y,y_tokenizer= tokenize(y)\n",
        "\n",
        "    preprocessed_x = pad(preprocessed_x)\n",
        "    preprocessed_y = pad(preprocessed_y)\n",
        "\n",
        "    #Keras's sparse_categorical_crossentropy requires the labels to be in 3 dimensions\n",
        "    preprocessed_y = preprocessed_y.reshape(*preprocessed_y.shape,1)\n",
        "\n",
        "    return preprocessed_x,preprocessed_y,x_tokenizer,y_tokenizer\n",
        "\n",
        "\n",
        "preprocessd_english_sentences,preprocessd_french_sentences,en_tokenizer,fr_tokenizer = preprocess(source_text,target_text)\n",
        "max_en_seq_length = preprocessd_english_sentences.shape[1]\n",
        "max_fr_seq_length = preprocessd_french_sentences.shape[1]\n",
        "en_vocab_size = len(en_tokenizer.word_index)\n",
        "fr_vocab_size = len(fr_tokenizer.word_index)\n",
        "print('Data Pre-Processed...')\n",
        "print('Max sequence length of English ',max_en_seq_length)\n",
        "print('Max sequence length of French ',max_fr_seq_length)\n",
        "print('Length of English dictionary ',en_vocab_size)\n",
        "print('Length of French dictionary ',fr_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Pre-Processed...\n",
            "Max sequence length of English  15\n",
            "Max sequence length of French  21\n",
            "Length of English dictionary  199\n",
            "Length of French dictionary  344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vACTA_Bye5Tp",
        "colab_type": "text"
      },
      "source": [
        "**Ids Back to text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn3EEIdccKXN",
        "colab_type": "code",
        "outputId": "3e546cdd-deaf-4240-f069-51543f1ffa0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Turn logits from a neural network into text using the tokenizer\n",
        "    :param logits: Logits from a neural network\n",
        "    :param tokenizer: Keras Tokenizer fit on the labels\n",
        "    :return: String that represents the text of the logits\n",
        "    \"\"\"\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "\n",
        "print('`logits_to_text` function loaded.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`logits_to_text` function loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E8LhDfQj0K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prOJEKhqfJ8l",
        "colab_type": "text"
      },
      "source": [
        "**Model 1** **RNN** <br>creating\n",
        "Simple RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBK-PL3HjQ_t",
        "colab_type": "code",
        "outputId": "a7c51a45-90e5-4e74-e8c1-2c3c7b403913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "\n",
        "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a basic RNN on x and y\n",
        "\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    # layer 1 uses an GRU module with english_vocab_size hidden units\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(GRU(english_vocab_size, return_sequences=True,\n",
        "                  input_shape=input_shape[1:]))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(10e-3),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Reshaping the input to work with a basic RNN\n",
        "tmp_x = pad(preprocessd_english_sentences, max_fr_seq_length)\n",
        "# print(tmp_x.shape)\n",
        "tmp_x = tmp_x.reshape((-1, preprocessd_french_sentences.shape[-2],1))\n",
        "# print(tmp_x.shape)\n",
        "# print((tmp_x.shape[1:][0]))\n",
        "# print(preprocessd_french_sentences.shape)\n",
        "\n",
        "# Build the model\n",
        "simple_rnn_model = simple_model(\n",
        "   tmp_x.shape,\n",
        "   max_fr_seq_length,\n",
        "   en_vocab_size,\n",
        "    fr_vocab_size)\n",
        "\n",
        "# print a summary of the model\n",
        "simple_rnn_model.summary()\n",
        "print('\\n')\n",
        "\n",
        "# Train the neural network\n",
        "simple_rnn_model.fit(tmp_x, preprocessd_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Print prediction(s)\n",
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], fr_tokenizer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_30 (GRU)                 (None, 21, 199)           119997    \n",
            "_________________________________________________________________\n",
            "time_distributed_22 (TimeDis (None, 21, 344)           68800     \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 21, 344)           0         \n",
            "=================================================================\n",
            "Total params: 188,797\n",
            "Trainable params: 188,797\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/10\n",
            "110288/110288 [==============================] - 10s 88us/step - loss: 1.7301 - acc: 0.5771 - val_loss: nan - val_acc: 0.6489\n",
            "Epoch 2/10\n",
            "110288/110288 [==============================] - 5s 46us/step - loss: 1.1324 - acc: 0.6594 - val_loss: nan - val_acc: 0.6683\n",
            "Epoch 3/10\n",
            "110288/110288 [==============================] - 5s 46us/step - loss: 1.0058 - acc: 0.6771 - val_loss: nan - val_acc: 0.6836\n",
            "Epoch 4/10\n",
            "110288/110288 [==============================] - 5s 46us/step - loss: 0.9383 - acc: 0.6907 - val_loss: nan - val_acc: 0.7010\n",
            "Epoch 5/10\n",
            "110288/110288 [==============================] - 5s 45us/step - loss: 0.8818 - acc: 0.7031 - val_loss: nan - val_acc: 0.7082\n",
            "Epoch 6/10\n",
            "110288/110288 [==============================] - 5s 46us/step - loss: 0.8405 - acc: 0.7147 - val_loss: nan - val_acc: 0.7155\n",
            "Epoch 7/10\n",
            "110288/110288 [==============================] - 5s 47us/step - loss: 0.8011 - acc: 0.7279 - val_loss: nan - val_acc: 0.7327\n",
            "Epoch 8/10\n",
            "110288/110288 [==============================] - 5s 47us/step - loss: 0.7673 - acc: 0.7404 - val_loss: nan - val_acc: 0.6973\n",
            "Epoch 9/10\n",
            "110288/110288 [==============================] - 5s 46us/step - loss: 0.7796 - acc: 0.7331 - val_loss: nan - val_acc: 0.7489\n",
            "Epoch 10/10\n",
            "110288/110288 [==============================] - 5s 45us/step - loss: 0.7231 - acc: 0.7592 - val_loss: nan - val_acc: 0.7372\n",
            "new jersey est parfois calme en l' et il est beau en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjRUEua0U0Do",
        "colab_type": "text"
      },
      "source": [
        "**Creating A RNN model using embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57YliRjQmoIK",
        "colab_type": "code",
        "outputId": "15ddeddc-cec8-42d9-99ea-37836955cb1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "def embed_model(input_shape, output_sequence_length, en_vocab_size, fr_vocab_size):\n",
        "    \"\"\"Bulid and train a RNN model using word embedding on x and y\n",
        "    params:\n",
        "        input_shape: tuple of input shape\n",
        "        output_sequnce_length: length of output sequence\n",
        "        en_vocab_size: Number of unique words in english dictionary\n",
        "        fr_vocab_size: Number of unique words in french dictionary\n",
        "        return:\n",
        "            RNN model built but not trained \n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    #Layer 1 uses embedding layer to enhance the word representation\n",
        "    model.add(Embedding(input_dim=en_vocab_size, output_dim=output_sequence_length,\n",
        "                        input_length=input_shape[1:][0]))    \n",
        "    #Layer 2 uses GRU with english vocab size hidden units\n",
        "    model.add(TimeDistributed(Dense(fr_vocab_size)))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(10e-3),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#Reshaping Input\n",
        "tmp_x = pad(preprocessd_english_sentences,max_fr_seq_length)\n",
        "#print('temp-x shape ',tmp_x.shape)\n",
        "#print('frnch sentence shape',preprocessd_french_sentences.shape)\n",
        "tmp_x = tmp_x.reshape((-1,preprocessd_french_sentences.shape[-2]))\n",
        "#print('final shape', tmp_x.shape)\n",
        "\n",
        "#Building the model\n",
        "embedded_rnn_model = embed_model(\n",
        "   tmp_x.shape,\n",
        "   max_fr_seq_length,\n",
        "   en_vocab_size,\n",
        "   fr_vocab_size)\n",
        "#Summary of the model\n",
        "embedded_rnn_model.summary()\n",
        "print('\\n')\n",
        "\n",
        "#Train the model\n",
        "embedded_rnn_model.fit(tmp_x, preprocessd_french_sentences, batch_size = 1024, epochs = 10, validation_split = 0.2)\n",
        "\n",
        "#Make Predictions\n",
        "print(logits_to_text(embedded_rnn_model.predict(tmp_x[:1])[0], fr_tokenizer))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 21, 21)            4179      \n",
            "_________________________________________________________________\n",
            "time_distributed_23 (TimeDis (None, 21, 344)           7568      \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 21, 344)           0         \n",
            "=================================================================\n",
            "Total params: 11,747\n",
            "Trainable params: 11,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/10\n",
            "110288/110288 [==============================] - 6s 55us/step - loss: 2.6757 - acc: 0.6246 - val_loss: nan - val_acc: 0.6662\n",
            "Epoch 2/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.4309 - acc: 0.6664 - val_loss: nan - val_acc: 0.6676\n",
            "Epoch 3/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3931 - acc: 0.6667 - val_loss: nan - val_acc: 0.6678\n",
            "Epoch 4/10\n",
            "110288/110288 [==============================] - 2s 16us/step - loss: 1.3809 - acc: 0.6669 - val_loss: nan - val_acc: 0.6677\n",
            "Epoch 5/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3752 - acc: 0.6668 - val_loss: nan - val_acc: 0.6672\n",
            "Epoch 6/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3724 - acc: 0.6668 - val_loss: nan - val_acc: 0.6675\n",
            "Epoch 7/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3704 - acc: 0.6669 - val_loss: nan - val_acc: 0.6676\n",
            "Epoch 8/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3691 - acc: 0.6668 - val_loss: nan - val_acc: 0.6677\n",
            "Epoch 9/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3681 - acc: 0.6669 - val_loss: nan - val_acc: 0.6679\n",
            "Epoch 10/10\n",
            "110288/110288 [==============================] - 2s 15us/step - loss: 1.3673 - acc: 0.6669 - val_loss: nan - val_acc: 0.6678\n",
            "new jersey est parfois calme en l' et il est enneigée en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58GfyNCiiVAJ",
        "colab_type": "text"
      },
      "source": [
        "**Bi-Directional RNN**<br> They are able to see future data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhjvBO1KclOL",
        "colab_type": "code",
        "outputId": "8605e984-895e-45c6-967b-aed4f9cead01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "def bidirectional_model(input_shape, output_sequence_length, en_vocab_size, fr_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and Train a bidirectional RNN model on x and y\n",
        "    params:\n",
        "        input_shape: tuple of input shape\n",
        "        output_sequnece_length: length of the output sequence\n",
        "        en_vocab_size: number of unique words in english dictionary\n",
        "        fr_vocab_size: number of unique word in french vocabulary\n",
        "        Return:\n",
        "    RNN model built but not trained\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    #Layer 1 is BiDirectional Wrapper and GRU layer\n",
        "    model.add(Bidirectional(GRU(en_vocab_size,return_sequences=True),input_shape=input_shape[1:]))\n",
        "    # A dense layer to the every temporal slice of an input. For each of step\n",
        "    # of the output sequence, decide which sequence should be chosen.\n",
        "    model.add(TimeDistributed(Dense(fr_vocab_size)))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(10e-3),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#Reshaping input\n",
        "tmp_x = pad(preprocessd_english_sentences,max_fr_seq_length)\n",
        "tmp_x = tmp_x.reshape((-1, preprocessd_french_sentences.shape[-2], 1))\n",
        "\n",
        "#Building Model\n",
        "\n",
        "bid_model = bidirectional_model(tmp_x.shape,\n",
        "                                max_fr_seq_length,\n",
        "                                en_vocab_size,\n",
        "                                fr_vocab_size)\n",
        "#Printing Summary of the model\n",
        "bid_model.summary()\n",
        "print('\\n')\n",
        "\n",
        "#Training Model\n",
        "bid_model.fit(tmp_x,preprocessd_french_sentences, batch_size = 1024, epochs = 10, validation_split = 0.2)\n",
        "\n",
        "# Making Prediction\n",
        "print(logits_to_text(bid_model.predict(tmp_x[:1])[0],fr_tokenizer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_10 (Bidirectio (None, 21, 398)           239994    \n",
            "_________________________________________________________________\n",
            "time_distributed_24 (TimeDis (None, 21, 344)           137256    \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 21, 344)           0         \n",
            "=================================================================\n",
            "Total params: 377,250\n",
            "Trainable params: 377,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/10\n",
            "110288/110288 [==============================] - 14s 128us/step - loss: 1.4668 - acc: 0.6206 - val_loss: nan - val_acc: 0.6747\n",
            "Epoch 2/10\n",
            "110288/110288 [==============================] - 9s 83us/step - loss: 0.9992 - acc: 0.6865 - val_loss: nan - val_acc: 0.6967\n",
            "Epoch 3/10\n",
            "110288/110288 [==============================] - 9s 80us/step - loss: 0.8790 - acc: 0.7042 - val_loss: nan - val_acc: 0.7148\n",
            "Epoch 4/10\n",
            "110288/110288 [==============================] - 9s 80us/step - loss: 0.8060 - acc: 0.7196 - val_loss: nan - val_acc: 0.7343\n",
            "Epoch 5/10\n",
            "110288/110288 [==============================] - 9s 78us/step - loss: 0.7786 - acc: 0.7299 - val_loss: nan - val_acc: 0.7384\n",
            "Epoch 6/10\n",
            "110288/110288 [==============================] - 9s 79us/step - loss: 0.7228 - acc: 0.7476 - val_loss: nan - val_acc: 0.7523\n",
            "Epoch 7/10\n",
            "110288/110288 [==============================] - 9s 79us/step - loss: 0.6920 - acc: 0.7574 - val_loss: nan - val_acc: 0.7317\n",
            "Epoch 8/10\n",
            "110288/110288 [==============================] - 9s 79us/step - loss: 0.6637 - acc: 0.7680 - val_loss: nan - val_acc: 0.7913\n",
            "Epoch 9/10\n",
            "110288/110288 [==============================] - 9s 82us/step - loss: 0.6351 - acc: 0.7766 - val_loss: nan - val_acc: 0.7965\n",
            "Epoch 10/10\n",
            "110288/110288 [==============================] - 9s 80us/step - loss: 0.6122 - acc: 0.7841 - val_loss: nan - val_acc: 0.7586\n",
            "new jersey est parfois calme au mois de il est il en en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov-dqdhwqUap",
        "colab_type": "text"
      },
      "source": [
        "**Encoder-Decoder Model**<br>\n",
        "Encoder creates a matrix and decoder takes this matrix and predicts output transaltion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeW94A-kmGBA",
        "colab_type": "code",
        "outputId": "31253a78-247b-4588-951f-eca27bb4257b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "source": [
        "def encod_decod_model(input_shape, output_sequence_length, en_vocab_size, fr_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and Train a encoder-decoder RNN model on x and y\n",
        "    params:\n",
        "        input_shape: tuple of input shape\n",
        "        output_sequnece_length: length of the output sequence\n",
        "        en_vocab_size: number of unique words in english dictionary\n",
        "        fr_vocab_size: number of unique word in french vocabulary\n",
        "        Return:\n",
        "    RNN model built but not trained\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    #The first network is encoder which accepts source language sentence, one word at a\n",
        "    #time and stores its overall meaning in a vector\n",
        "    #Encoder network is not used to produce any output\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(GRU(en_vocab_size, return_sequences=False,\n",
        "                  input_shape=input_shape[1:]))\n",
        "    model.add(Dense(fr_vocab_size))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # The second network is called decoder which takes vector from encoder and \n",
        "    #expands it into the transaltion of target language, one word at a time\n",
        "    \n",
        "    #Get the last output of GRU and repeat it\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(GRU(en_vocab_size, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(fr_vocab_size)))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(10e-3),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "#Reshaping input\n",
        "tmp_x = pad(preprocessd_english_sentences,max_fr_seq_length)\n",
        "tmp_x = tmp_x.reshape((-1, preprocessd_french_sentences.shape[-2], 1))\n",
        "\n",
        "#Building Model\n",
        "\n",
        "enc_dec_model = encod_decod_model(tmp_x.shape,\n",
        "                                max_fr_seq_length,\n",
        "                                en_vocab_size,\n",
        "                                fr_vocab_size)\n",
        "#Printing Summary of the model\n",
        "enc_dec_model.summary()\n",
        "print('\\n')\n",
        "\n",
        "#Training Model\n",
        "enc_dec_model.fit(tmp_x,preprocessd_french_sentences, batch_size = 1024, epochs = 10, validation_split = 0.2)\n",
        "\n",
        "# Making Prediction\n",
        "print(logits_to_text(bid_model.predict(tmp_x[:1])[0],fr_tokenizer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_32 (GRU)                 (None, 199)               119997    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 344)               68800     \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 344)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_9 (RepeatVecto (None, 21, 344)           0         \n",
            "_________________________________________________________________\n",
            "gru_33 (GRU)                 (None, 21, 199)           324768    \n",
            "_________________________________________________________________\n",
            "time_distributed_25 (TimeDis (None, 21, 344)           68800     \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 21, 344)           0         \n",
            "=================================================================\n",
            "Total params: 582,365\n",
            "Trainable params: 582,365\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/10\n",
            "110288/110288 [==============================] - 15s 136us/step - loss: 2.7774 - acc: 0.4489 - val_loss: nan - val_acc: 0.5401\n",
            "Epoch 2/10\n",
            "110288/110288 [==============================] - 9s 86us/step - loss: 1.8315 - acc: 0.5504 - val_loss: nan - val_acc: 0.5898\n",
            "Epoch 3/10\n",
            "110288/110288 [==============================] - 9s 85us/step - loss: 1.4952 - acc: 0.5968 - val_loss: nan - val_acc: 0.5931\n",
            "Epoch 4/10\n",
            "110288/110288 [==============================] - 10s 87us/step - loss: 1.3480 - acc: 0.6224 - val_loss: nan - val_acc: 0.6359\n",
            "Epoch 5/10\n",
            "110288/110288 [==============================] - 10s 87us/step - loss: 1.2774 - acc: 0.6368 - val_loss: nan - val_acc: 0.6541\n",
            "Epoch 6/10\n",
            "110288/110288 [==============================] - 10s 86us/step - loss: 1.2794 - acc: 0.6380 - val_loss: nan - val_acc: 0.6506\n",
            "Epoch 7/10\n",
            "110288/110288 [==============================] - 9s 84us/step - loss: 1.2286 - acc: 0.6473 - val_loss: nan - val_acc: 0.6583\n",
            "Epoch 8/10\n",
            "110288/110288 [==============================] - 9s 85us/step - loss: 1.2277 - acc: 0.6500 - val_loss: nan - val_acc: 0.6394\n",
            "Epoch 9/10\n",
            "110288/110288 [==============================] - 9s 84us/step - loss: 1.2059 - acc: 0.6488 - val_loss: nan - val_acc: 0.6540\n",
            "Epoch 10/10\n",
            "110288/110288 [==============================] - 9s 86us/step - loss: 1.1787 - acc: 0.6567 - val_loss: nan - val_acc: 0.6665\n",
            "new jersey est parfois calme au mois de il est il en en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkM6Z_OUuyN_",
        "colab_type": "text"
      },
      "source": [
        "**Final Model**<br>Custom Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z31YGqlBtdTe",
        "colab_type": "code",
        "outputId": "079fdbd4-3468-4b73-ad1c-3f2958342ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "def final_model(input_shape, output_sequence_length, en_vocab_size, fr_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and Train a RNN model that incorporates embedding, encoder-decoder, bidirectional on x and y\n",
        "    params:\n",
        "        input_shape: tuple of input shape\n",
        "        output_sequnece_length: length of the output sequence\n",
        "        en_vocab_size: number of unique words in english dictionary\n",
        "        fr_vocab_size: number of unique word in french vocabulary\n",
        "        Return:\n",
        "    RNN model built but not trained\n",
        "    \"\"\"  \n",
        "    model = Sequential()\n",
        "\n",
        "    #Layer 1 is uses embedding layer\n",
        "    model.add(Embedding(input_dim=en_vocab_size, output_dim=output_sequence_length,\n",
        "                        input_length=input_shape[1:][0])) \n",
        "    #Layer 2 Uses Bidirectional Wrapper and GRU Layer\n",
        "    model.add(Bidirectional(GRU(en_vocab_size, return_sequences=False),\n",
        "                                input_shape=input_shape[1:])) \n",
        "    #Layer 3 Uses Encode layer\n",
        "    model.add(Dense(fr_vocab_size))\n",
        "    model.add(Activation('relu'))\n",
        "    #Layer 4 uses decoder layer\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(Bidirectional(GRU(en_vocab_size, return_sequences=True)))\n",
        "    #Layer 5 is dense layer\n",
        "    model.add(TimeDistributed(Dense(fr_vocab_size)))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(10e-3),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#Building Model\n",
        "\n",
        "final_rnn_model = final_model(preprocessd_english_sentences.shape,\n",
        "                                max_fr_seq_length,\n",
        "                                en_vocab_size,\n",
        "                                fr_vocab_size)\n",
        "#Printing Summary of the model\n",
        "final_rnn_model.summary()\n",
        "print('\\n')\n",
        "\n",
        "#Training Model\n",
        "final_rnn_model.fit(preprocessd_english_sentences,preprocessd_french_sentences, batch_size = 1024, epochs = 10, validation_split = 0.2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 15, 21)            4179      \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 398)               263874    \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 344)               137256    \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 344)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_10 (RepeatVect (None, 21, 344)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 21, 398)           649536    \n",
            "_________________________________________________________________\n",
            "time_distributed_26 (TimeDis (None, 21, 344)           137256    \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 21, 344)           0         \n",
            "=================================================================\n",
            "Total params: 1,192,101\n",
            "Trainable params: 1,192,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/10\n",
            "110288/110288 [==============================] - 23s 212us/step - loss: 2.3651 - acc: 0.4924 - val_loss: nan - val_acc: 0.6156\n",
            "Epoch 2/10\n",
            "110288/110288 [==============================] - 17s 151us/step - loss: 1.1347 - acc: 0.6804 - val_loss: nan - val_acc: 0.7238\n",
            "Epoch 3/10\n",
            "110288/110288 [==============================] - 16s 149us/step - loss: 0.8531 - acc: 0.7446 - val_loss: nan - val_acc: 0.7783\n",
            "Epoch 4/10\n",
            "110288/110288 [==============================] - 16s 146us/step - loss: 0.6546 - acc: 0.7999 - val_loss: nan - val_acc: 0.8322\n",
            "Epoch 5/10\n",
            "110288/110288 [==============================] - 16s 148us/step - loss: 0.4813 - acc: 0.8495 - val_loss: nan - val_acc: 0.8744\n",
            "Epoch 6/10\n",
            "110288/110288 [==============================] - 16s 149us/step - loss: 0.3221 - acc: 0.9007 - val_loss: nan - val_acc: 0.9001\n",
            "Epoch 7/10\n",
            "110288/110288 [==============================] - 16s 148us/step - loss: 0.2338 - acc: 0.9284 - val_loss: nan - val_acc: 0.9438\n",
            "Epoch 8/10\n",
            "110288/110288 [==============================] - 16s 147us/step - loss: 0.1781 - acc: 0.9454 - val_loss: nan - val_acc: 0.9492\n",
            "Epoch 9/10\n",
            "110288/110288 [==============================] - 16s 148us/step - loss: 0.1615 - acc: 0.9503 - val_loss: nan - val_acc: 0.9528\n",
            "Epoch 10/10\n",
            "110288/110288 [==============================] - 17s 151us/step - loss: 0.1685 - acc: 0.9479 - val_loss: nan - val_acc: 0.9473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fceec93e6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jOGzkX_yDhI",
        "colab_type": "code",
        "outputId": "7bddbc18-128a-4493-af2d-68a91d4f1825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "    \n",
        "    ## Making final predictions\n",
        "    y_id_to_word = {value: key for key, value in fr_tokenizer.word_index.items()}\n",
        "    y_id_to_word[0] = '<EOD>'\n",
        "\n",
        "    sentence = 'he saw a old yellow truck'\n",
        "    sentence = [en_tokenizer.word_index[word] for word in sentence.split()]\n",
        "    sentence = pad_sequences([sentence], maxlen=preprocessd_english_sentences.shape[-1], padding='post')\n",
        "    sentences = np.array([sentence[0], preprocessd_english_sentences[0]])\n",
        "    predictions = final_rnn_model.predict(sentences, len(sentences))\n",
        "\n",
        "    print('Sample 1:')\n",
        "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
        "    print('Il a vu un vieux camion jaune')\n",
        "    print('Sample 2:')\n",
        "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
        "    print(' '.join([y_id_to_word[np.max(x)] for x in preprocessd_french_sentences[0]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample 1:\n",
            "il a vu un vieux camion jaune <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD>\n",
            "Il a vu un vieux camion jaune\n",
            "Sample 2:\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD>\n",
            "new jersey est parfois calme pendant l' automne et il est neigeux en avril <EOD> <EOD> <EOD> <EOD> <EOD> <EOD> <EOD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3Fh405M1w67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}